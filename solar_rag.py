import time
import os, getpass, base64, uuid, tempfile
from typing import Dict, List, Any, Optional
import streamlit as st

from langchain_upstage import ChatUpstage, UpstageEmbeddings 
from langchain_chroma import Chroma
from langchain_community.document_loaders import PyPDFLoader

from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, SystemMessage

from langsmith import Client

# ğŸ”¹ ì¶”ê°€: utils_rag.pyì—ì„œ Streamlitìš© í•¨ìˆ˜ì™€ í•¸ë“¤ëŸ¬ ê°€ì ¸ì˜¤ê¸°
from utils_rag import init_conversation, print_conversation, StreamHandler

# ğŸ”¹ ì¶”ê°€: Redis ê¸°ë°˜ ì±„íŒ… ê¸°ë¡ (LangChain RedisChatMessageHistory ì‚¬ìš©)
from langchain_community.chat_message_histories import RedisChatMessageHistory

from dotenv import load_dotenv


# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ë¶ˆëŸ¬ì˜¨ ê°’ í™•ì¸ (ë””ë²„ê¹…ìš©, ì‹¤ì œ ì½”ë“œì—ì„  printëŠ” ì§€ì›Œë„ ë¨)
print("UPSTAGE_API_KEY:", os.getenv("UPSTAGE_API_KEY"))
print("LANGCHAIN_API_KEY:", os.getenv("LANGCHAIN_API_KEY"))

# ğŸ”¹ ì¶”ê°€: Redis ì„œë²„ì˜ URL ë¶ˆëŸ¬ì˜¤ê¸°
# GCP Docker Redis URL
REDIS_URL = os.getenv("REDIS_URL")

# LangSmith client ì„¤ì •
client = Client()  # envë¡œë¶€í„° ìë™ ì„¤ì •
# í”„ë¡œì íŠ¸ ëª©ë¡ì´ ë³´ì´ë©´ ì¸ì¦ OK
projects = list(client.list_projects())[:3]
print("LangSmith projects (sample):", [p.name for p in projects] or "(none)")

# LLMê³¼ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
# Upstage ëª¨ë¸: ê¸°ë³¸ê°’(ì„œë²„ ë””í´íŠ¸) ì‚¬ìš© â€” í•„ìš” ì‹œ model="solar-pro-2" ë“±ìœ¼ë¡œ ì§€ì • ê°€ëŠ¥
llm = ChatUpstage(temperature=0.2)  # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ê¶Œì¥: temperature=0.2
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ëŠ” ì‹œë‹ˆì–´ AI ë©˜í† ì•¼."),
    ("human", "{question}")
])
chain = prompt | llm | StrOutputParser()

if "chain_test_done" not in st.session_state:
    chain_test_result = chain.invoke({"question": "Streamlitì˜ placeholder ìš©ë„ í•œ ì¤„ë¡œ ì„¤ëª…í•´ì¤˜."})
    print(chain_test_result)
    st.session_state.chain_test_done = True

# ğŸ”¹ ì£¼ì„ ì²˜ë¦¬ ë¶€ë¶„:
# ê¸°ì¡´ ë¡œì»¬ ì„¸ì…˜ ì´ˆê¸°í™” ë¶€ë¶„(UUID ìƒì„± ë° file_cache)
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
#if "id" not in st.session_state:
#    st.session_state.id = uuid.uuid4()
#    st.session_state.file_cache = {} 
# ì„¸ì…˜ ID ì„¤ì •
#session_id = st.session_state.id
#client = None

# ì±„íŒ… ì´ˆê¸°í™” í•¨ìˆ˜
def reset_chat():
    st.session_state.messages = []
    st.session_state.context = None

# PDF íŒŒì¼ ë””ìŠ¤í”Œë ˆì´ í•¨ìˆ˜ ì •ì˜
def display_pdf(file):
    st.markdown("### PDF Preview ###")
    base64_pdf = base64.b64encode(file.read()).decode("utf-8")
    pdf_display = f"""<iframe src="data:application/pdf;base64,{base64_pdf}" width="400" height="100%" type="application/pdf" style="height:100vh; width:100%"></iframe>"""
    st.markdown(pdf_display, unsafe_allow_html=True)
    
# ğŸ”¹ ì¶”ê°€: Redis ê¸°ë°˜ ë©”ì‹œì§€ ê¸°ë¡ ê°ì²´ ìƒì„± í•¨ìˆ˜
def get_redis_message_history(session_id: str):
    return RedisChatMessageHistory(session_id=session_id, url=REDIS_URL)

# ì‚¬ì´ë“œë°” êµ¬ì„± - ì„¸ì…˜ ID ì…ë ¥(ğŸ”¹ ì¶”ê°€), PDF ì—…ë¡œë“œ
with st.sidebar:
    session_id = st.text_input("Session IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="example1234")
    clear_space = st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")
    if clear_space:
        st.session_state["messages"] = []
        st.rerun()
        
    st.header(f"Add your documents!")
    uploaded_file = st.file_uploader("Choose your `.pdf` file", type="pdf")
    # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
    if uploaded_file:
        print(uploaded_file)
        try:
            file_key = f"{session_id}-{uploaded_file.name}"
            st.write("Indexing your document...")
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± ë° íŒŒì¼ ì €ì¥
            with tempfile.TemporaryDirectory() as temp_dir:
                file_path = os.path.join(temp_dir, uploaded_file.name)
                print("file path:", file_path)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getvalue())
                
                # PDF ë¡œë” ìƒì„± ë° ë¬¸ì„œ ë¶„í• 
                if file_key not in st.session_state.get('file_cache', {}):
                    if os.path.exists(temp_dir):
                        print("temp_dir:", temp_dir)
                        loader = PyPDFLoader(file_path)
                    # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ì—ëŸ¬ ì²˜ë¦¬
                    else:
                        st.error('Could not find the file you uploaded, please check again...')
                        st.stop()
                    # í˜ì´ì§€ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                    pages = loader.load_and_split()
                    
                    # ğŸ”¹ ì¶”ê°€: ì‚¬ì´ë“œë°”ì—ì„œ í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
                    for i, p in enumerate(pages[:3]):
                        st.write(f"Page {i} content preview:", p.page_content[:200])
                    
                    # í¬ë¡œë§ˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                    # í¬ë¡œë§ˆì—ì„œ ìì—°ì–´ë¥¼ ë²¡í„°ë¡œ, ë²¡í„°ë¥¼ ìì—°ì–´ë¡œ ì²˜ë¦¬í•´ì¤€ë‹¤.
                    # í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” PDF íŒŒì¼ì´ì–´ì•¼ í•¨.
                    # ìŠ¤ìº”ëœ PDF íŒŒì¼ì¸ ê²½ìš° OCRì„ ì´ìš©í•´ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ pagesì— ì €ì¥ í›„ ë„˜ê²¨ ì¤˜ì•¼ í•¨.
                    vectorstore = Chroma.from_documents(pages, UpstageEmbeddings(model="solar-embedding-1-large"))
                    # ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
                    retriever = vectorstore.as_retriever(k=3) # ê²€ìƒ‰ ë²”ìœ„ë¥¼ 3ê°œë¡œ í™•ì¥ (ìˆ˜ì •)

                    # ì±—ë´‡ ìƒì„±
                    # ChatUpstage ê°ì²´ ìƒì„±
                    api_key = os.getenv("UPSTAGE_API_KEY")
                    chat = ChatUpstage(api_key=api_key)

                    # ì§ˆë¬¸ ì¬êµ¬ì„± í”„ë¡¬í”„íŠ¸(íˆìŠ¤í† ë¦¬ ì°¸ê³ ìš©)
                    # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
                    contextualize_q_system_prompt = (
                        "ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ì´ ìˆì„ ë•Œ, "
                        "ì´ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                        "ì´ëŸ° ê²½ìš°, ëŒ€í™” ë‚´ìš©ì„ ì•Œ í•„ìš” ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”. "
                        "ì§ˆë¬¸ì— ë‹µí•  í•„ìš”ëŠ” ì—†ê³ , í•„ìš”í•˜ë‹¤ë©´ ê·¸ì € ë‹¤ì‹œ êµ¬ì„±í•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”. "
                        "íŠ¹íˆ 'í˜ì´ì§€ ë²ˆí˜¸'ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ í•´ë‹¹ í˜ì´ì§€ í…ìŠ¤íŠ¸ë§Œ ì°¸ì¡°í•˜ë„ë¡ í•˜ì„¸ìš”."
                    )
                    contextualize_q_prompt = ChatPromptTemplate.from_messages(
                        [
                            ("system", contextualize_q_system_prompt),
                            MessagesPlaceholder("chat_history"),
                            ("human", "{input}"),
                        ]
                    )
                    # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
                    history_aware_retriever = create_history_aware_retriever(
                        chat, retriever, contextualize_q_prompt
                    )

                    # ì§ˆë¬¸ ë‹µë³€ ì²´ì¸ ìƒì„±
                    qa_system_prompt = (
                        "ë‹¹ì‹ ì€ PDFì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë³´ì¡°ì›ì…ë‹ˆë‹¤. "
                        "PDF ë‚´ìš© ì™¸ì—ëŠ” ì–´ë–¤ ì§€ì‹ë„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. "
                        "ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”. "
                        "ë‹µë³€ì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. "
                        "ë‹µë³€ì€ 10ë¬¸ì¥ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ì§€ë§Œ í•µì‹¬ê³¼ ì¦ê±°ë¥¼ í¬í•¨í•˜ì„¸ìš”. "
                        "ì§ˆë¬¸ì— íŠ¹ì • í˜ì´ì§€ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í•´ë‹¹ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. "
                        "## ë‹µë³€ ì˜ˆì‹œ\nğŸ“ë‹µë³€ ë‚´ìš©:\nğŸ“ì¦ê±°:\n{context}")
                    qa_prompt = ChatPromptTemplate.from_messages(
                        [
                            ("system", qa_system_prompt),
                            MessagesPlaceholder("chat_history"),
                            ("human", "{input}"),
                        ]
                    )
                    question_answer_chain = create_stuff_documents_chain(chat, qa_prompt)
                    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
                    
                    # ğŸ”¹ ì¶”ê°€: Redisì— ì—…ë¡œë“œí•œ PDF íŒŒì¼ëª…ë§Œ ì €ì¥
                    redis_history = get_redis_message_history(session_id)
                    redis_history.add_user_message(f"ì—…ë¡œë“œ íŒŒì¼: {uploaded_file.name}")
                    
                    # PDF íŒŒì¼ ë””ìŠ¤í”Œë ˆì´
                    st.success("Ready to Chat!")
                    display_pdf(uploaded_file)
                    
                    # RAG ë””ë²„ê¹…ìš©: í˜ì´ì§€ ë‚´ìš© í™•ì¸ (ì¶”ê°€)
                    for i, p in enumerate(pages[:3]):
                        print(f"Page {i} content preview:", p.page_content[:200])
        except Exception as e:
                st.error(f"An error occuered : {e}")
                st.stop()

# ğŸ”¹ ì¶”ê°€ ë° ìˆ˜ì •: í˜ì´ì§€ í‘œì‹œ ë° íƒ€ì´í‹€ ì…ë ¥
st.set_page_config(page_title="Upload Text PDF And Chat",page_icon="ğŸ§‘â€ğŸš€")
st.title("ğŸ§‘â€ğŸš€ Askument")

# ğŸ”˜ ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
if st.button("ì±„íŒ… ì´ˆê¸°í™” ğŸ—‘ï¸"):
    reset_chat()
    st.rerun()

# íŒŒì¼ ì…ë ¥í•˜ê³  ì‹œë„í•˜ë„ë¡ ì–¼ëŸ¿ ì¶”ê°€
if not uploaded_file:
    st.toast("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì…”ì•¼ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ğŸ”¹ ì£¼ì„ ì²˜ë¦¬ ë¶€ë¶„:
# utils_rag.py íŒŒì¼ì— ì •ì˜í•œ init_conversation()ê³¼ print_conversation() ë©”ì„œë“œë¡œ ëŒ€ì²´(ì½”ë“œë¥¼ ë” ì§§ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë¶„ë¦¬ ë° StreamHandler ë“±ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ ë” í¸ë¦¬.) 
# ë©”ì„¸ì§€ ì´ˆê¸°í™”
#if "messages" not in st.session_state:
#    st.session_state.messages = []
# ê¸°ì¡´ ë©”ì„¸ì§€ í‘œì‹œ
#for message in st.session_state.messages:
#    with st.chat_message(message["role"]): # role = user, assistant
#        st.markdown(message["content"])

# ğŸ”¹ ì¶”ê°€: utils_rag.py íŒŒì¼ì— ì •ì˜í•œ ë©”ì„œë“œ í™œìš©(ë°”ë¡œ ìœ„ ì£¼ì„ ì½”ë“œ ëŒ€ì²´) - ì„¸ì…˜ ì´ˆê¸°í™” ë° ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥
init_conversation()
print_conversation()

# ê¸°ë¡í•˜ëŠ” ëŒ€í™”ì˜ ìµœëŒ€ê°¯ìˆ˜ ì„¤ì •
MAX_MESSAGES_BEFORE_DELETION = 12

# ìœ ì € ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”!"):
    if len(st.session_state.messages) >= MAX_MESSAGES_BEFORE_DELETION:
        # ì´ ë¶€ë¶„ì—ì„œ ì„¸ì…˜ì˜ Maxí¬ê¸°(ì§€ê¸ˆì€ 12ê°œ)ë¥¼ ë„˜ì–´ê°€ë©´ 2ê°œë¥¼ ì§€ìš°ëŠ” ì´ìœ ëŠ” ì…ë ¥, ì¶œë ¥ 2ê°œì´ê¸° ë•Œë¬¸ì— 2ê°œë¥¼ ì§€ìš°ëŠ” ê²ƒ! ê¸°ì–µ!
        del st.session_state.messages[0]
        del st.session_state.messages[0]
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µì²˜ë¦¬
    with st.chat_message("assistant"):
        message_placeholder = st.empty() # ì—¬ê¸°ë¥¼ ë¹ˆì¹¸ìœ¼ë¡œ ë§Œë“¤ì—ˆë‹¤ê°€
        full_response = ""
        
        # ğŸ”¹ ì¶”ê°€: StreamHandler ê°ì²´ ìƒì„±
        handler = StreamHandler(message_placeholder)
        # ğŸ”¹ ì¶”ê°€: "callbacks": [handler] ë¶€ë¶„ ì¶”ê°€í•˜ì—¬ StreamHandlerë¥¼ ì´ìš©í•˜ì—¬ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°
        result = rag_chain.invoke({"input": prompt, "chat_history": st.session_state.messages, "callbacks": [handler]})
        
        # ê²€ìƒ‰ëœ context í™•ì¸ (ì¶”ê°€)
        # ì°¸ê³ í•œ ìë£Œ, ë¬¸ë§¥ í‘œì‹œ
        with st.expander("ì°¸ê³ í•œ ë¶€ë¶„"):
            st.write(result.get("context", "ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ"))
        
        # ğŸ”¹ ì£¼ì„ ì²˜ë¦¬ ë¶€ë¶„:
        # StreamHandler ê°ì²´ ì‚¬ìš©í•˜ì§€ ì•Šì„ ì‹œ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ì„ ìœ„í•¨
        # í•œ ë‹¨ì–´ì”© message_placeholderì— í‘œì‹œë¨
        # StreamHandlerë¥¼ ì‚¬ìš©í•˜ë©´ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ
        # êµ³ì´ í•´ë‹¹ ë¶€ë¶„ì„ ë‚¨ê¸¸ í•„ìš” ì—†ìŒ.
        #for chunk in result["answer"].split(" "):
            # print("ëª¨ë¸ì˜ ì¶œë ¥ê°’", result["answer"])
            # print(chunk)
        #    full_response += chunk + " "
        #    time.sleep(0.2)
            # ì´ ë¶€ë¶„ì—ì„œ message_placeholderë¥¼ ì±„ìš°ëŠ” ë¶€ë¶„
        #    message_placeholder.markdown(full_response+ "â–Œ")
        #message_placeholder.markdown(full_response)
                
        st.session_state.messages.append(
            {"role": "assistant","content": full_response})